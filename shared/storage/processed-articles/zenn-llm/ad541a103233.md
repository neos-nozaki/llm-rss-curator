---
title: プロンプトエンジニアリング、RAG、ファインチューニング、の違いを直感的に理解しよう
url: https://zenn.dev/kouch/articles/9338930c27f02c
author: Kouch Sato
published: Mon, 10 Nov 2025 11:58:33 GMT
feed: zenn-llm
---

## 🎯 この記事の要点

この記事は、プロンプトエンジニアリング、RAG（Retrieval Augmented Generation）、ファインチューニングの3つの手法を通じて、LLM（大規模言語モデル）に対して求められる答えを引き出す方法を解説しています。各手法は、LLMが試験問題に答える様子に例えられ、プロンプトエンジニアリングは問題文の工夫、RAGは外部情報の参照、ファインチューニングは事前の深い学習として説明されています。

## 📚 背景・コンテキスト

生成AIやLLMは、ユーザーの入力に対して適切な出力を生成することが求められます。しかし、モデルの事前学習には限界があり、特定の知識や最新情報を必要とする場合には工夫が必要です。これらの手法は、LLMの出力をより正確かつ有用にするために開発されました。

## 🔍 技術的な詳細

- **プロンプトエンジニアリング**: 入力文を工夫して、LLMが望ましい出力を生成するように誘導する手法。具体的には、回答形式や内容を指定することで、モデルの出力を制御します。
  
- **RAG（Retrieval Augmented Generation）**: 外部の知識をLLMに与え、検索して拡張された回答を生成する方法。Embeddingを用いて外部情報を数値化し、類似情報を検索してコンテキストとして使用します。

- **ファインチューニング**: 特定の分野に特化した知識をモデルに学習させるプロセス。事前にモデルを再学習させることで、一貫した出力を可能にします。これは時間とコストがかかりますが、RAGよりも深い知識を埋め込むことができます。

## 💡 実践的な示唆

- プロンプトエンジニアリングは、手軽に試せる方法であり、特定の出力を必要とする場面で有効です。
- RAGは、最新情報や独自データが必要な場合に活用でき、特にカスタマーサポートの自動化に適しています。
- ファインチューニングは、特定のドメインにおける深い知識が必要な場合に有効で、特定のキャラクターや専門分野に特化したLLMを作成するのに適しています。

## 👥 対象読者

- LLMを活用したプロダクト開発に関心がある技術者
- 生成AIの出力を改善したいと考えているデータサイエンティスト
- AIを活用したサービスを提供する企業の技術担当者

## 🏷️ キーワード

プロンプトエンジニアリング, RAG, ファインチューニング, LLM, 生成AI, Embedding, VectorDB, MLOps, Google Vertex AI